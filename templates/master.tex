%==== PACKAGES AND OTHER DOCUMENT CONFIGURATIONS  ====%
\documentclass{resume} % Use the custom resume.cls style
\usepackage[left=0.25in,top=0.25in,right=0.25in,bottom=0.25in]{geometry} % Document margins
\usepackage[T1]{fontenc}
\usepackage{xcolor}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{fontawesome} % For GitHub and LinkedIn symbols
\usepackage{textcomp} % For mobile phone and email symbols
% \usepackage[colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}
\usepackage{xcolor}  % Required for defining custom colors
\usepackage{hyperref}
% Define your custom colors
% \definecolor{myblue}{RGB}{173, 216, 246}
% \definecolor{myblue}{RGB}{123, 176, 206}
\definecolor{myblue}{RGB}{0, 164, 218}

% Set hyperlink colors
\hypersetup{
    colorlinks=true,
    linkcolor=myblue,
    citecolor=myblue,
    urlcolor=myblue
}

\usepackage{hyperref}

%==== Headings ====%
\name{Aaron Dankert} % Your name
\address{
{\faPhone} \href{tel:(505) 507{-}8207}{(505)507{-}8207} \quad {\faEnvelope} \href{mailto:aarondankert@gmail.com}{aarondankert@gmail.com} \quad {\faGithub} \href{https://github.com/aa{-}dank}{https://github.com/aa{-}dank} \quad {\faLinkedin} \href{https://www.linkedin.com/in/aadank/}{https://www.linkedin.com/in/aadank/} }

\begin{document}

%===== WORK EXPERIENCE SECTION =====%
    \begin{rSection}{Work Experience}
                    \begin{rSubsection}
                {Systems Analyst}{2023 - Present}
                                    {\normalfont{\textit{University of California, Santa Cruz}}}
                                {\normalfont{\textit{Santa Cruz, CA, USA}}}
                                    \item Enhanced department's online presence by managing several websites and building new web assets
                                    \item Continued development of a comprehensive archives application.
                                    \item Authored over 10,000 words of technical documentation, facilitating improved process understanding and compliance.
                                    \item Administered databases using SQL and JSON.
                                    \item Led a successful migration from CMiC Project Managment Software to FileMaker, writing scripts for data extraction and integration.
                                    \item Implemented data cleaning techniques to increase data integrity.
                                    \item Created comprehensive technical documentation for various processes, ensuring consistency and accuracy, facilitating seamless knowledge transfer.
                                    \item Produced technical documentation and communications for diverse audiences.
                            \end{rSubsection}
                    \begin{rSubsection}
                {Archives Manager}{2020 - 2023}
                                    {\normalfont{\textit{University of California, Santa Cruz}}}
                                {\normalfont{\textit{Santa Cruz, CA, USA}}}
                                    \item Streamlined file management and access by developing a comprehensive archives application, reducing archiving and retrieval overead.
                                    \item Enhanced database accuracy and security by implementing data scraping and Google authentication.
                                    \item Improved user experience and task automation by designing a user{-}friendly web interface.
                                    \item Extensive archiving processes and procedure overhaul, reducing archiving errors by at least 40\%.
                                    \item Enhanced data presentation by utilizing statistical graphics software for data visualization.
                                    \item Created technical documentation, reducing onboarding time for new staff by 20\% and facilitating the adoption of new data science methodologies.
                                    \item Led a successful migration from CMiC Project Managment Software to FileMaker, writing scripts for data extraction and integration.
                                    \item Lead a team of 6 Employees.
                            \end{rSubsection}
                    \begin{rSubsection}
                {Data Coordinator}{2017 - 2020}
                                    {\normalfont{\textit{University of California, Santa Cruz}}}
                                {\normalfont{\textit{Santa Cruz, CA, USA}}}
                                    \item Provided project engineering support for \$900million in Capital Projects.
                                    \item Enhanced departmental online presence by managing and building web assets.
                                    \item Improved data quality and integrity by further exploitation of existing tools to improve the most important process of my position.
                                    \item Managed sensitive data under regulatory standards, ensuring 100\% compliance.
                                    \item Generated actionable insights by conducting statistical data processing using advanced tools.
                                    \item Optimized financial tracking and reporting by building spreadsheets for process summaries.
                            \end{rSubsection}
            \end{rSection}

%==== EDUCATION SECTION ====%
\begin{rSection}{Education}
                        \textbf{University of Michigan, Ann Arbor, USA} \hfill {2023 - 2025} \\
                            {Masters in Data Science}
                         
             
         
                        \textbf{University of New Mexico, Albuquerque, USA} \hfill {2006 - 2010} \\
                            {Bachelors in Psychology and Economics} 
    \end{rSection}

% ==== PROJECTS SECTION =====%
    \begin{rSection}{Projects}
                    \begin{rSubsection}
                                    {\href{https://github.com/aa{-}dank/x{-}domain{-}llm{-}classification}{LLM Attribution: Challenges and Insights Across Model Stochasticity}}
                                {\normalfont{ - }}{}{}
                                    \item Conducted quantitative analysis on LLM{-}generated text by implementing Random Forest, Logistic Regression, Deep Learning models.
                                    \item Utilized t{-}SNE and Principal Component Analysis to visualize high{-}dimensional embeddings.
                                    \item Trained and evaluated machine learning and deep learning models to classify LLM{-}generated text based on originating model.
                                    \item Engineered a text classification system by implementing Random Forest and Logistic Regression models using scikit{-}learn and PyTorch.
                                    \item Conducted advanced data analysis leveraging t{-}SNE and Principal Component Analysis to visualize complex data relationships, contributing to clearer insights for forecasting efforts.
                            \end{rSubsection}
                    \begin{rSubsection}
                                    {\href{https://github.com/aa{-}dank/archives\_app}{Archives App}}
                                {\normalfont{ - }}{}{}
                                    \item Developed a data{-}driven Archives Application using Python, Flask, and PostgreSQL, streamlining archival file management.
                                    \item Includes timekeeping functionality and data visualization tools for tracking employee productivity and archiving progress.
                                    \item Implemented data scraping techniques to maintain an up{-}to{-}date database.
                                    \item Optimized application performance by integrating Redis for background tasks, ensuring scalability and responsiveness.
                                    \item Integrated Google authentication and role{-}based access control, enhancing user security and compliance with organizational standards.
                                    \item Designed RESTful API endpoints to automate and optimize data interactions, reducing manual data handling efforts by 60\%.
                                    \item Facilitated user adoption of new technology by designing an intuitive web interface and RESTful API endpoints, improving user interaction and task automation.
                                    \item Developed a comprehensive archives application using Flask that enhanced file organization and access efficiency, meeting business needs for structured data management.
                            \end{rSubsection}
                    \begin{rSubsection}
                                    {\href{https://github.com/aa{-}dank/archives\_archiver}{Archiving Desktop Application}}
                                {\normalfont{Sep 2023 - Dec 2023}}{}{}
                                    \item Developed a standalone desktop application using SQLite for efficient document archiving, increasing tracking and reporting accuracy by 25\%.
                                    \item Implemented a robust backup solution for the web{-}based archiving system, reducing data loss risk and enhancing data security.
                                    \item Streamlined document management processes by automating file tracking, achieving an estimated 35\% reduction in manual archiving time.
                                    \item Developed a standalone desktop application with an intuitive PySimpleGUI interface, streamlining document archiving and improving workflow efficiency by >50\%.
                                    \item Integrated SQLite database solutions to track and manage archived files, enhancing data organization and deployment efficiency.
                        \end{rSubsection}
            \end{rSection}

%==== TECHNICAL STRENGTHS SECTION ====%
    \begin{rSection}{Technical Skills}
        \begin{tabular}{ @{} l @{\hspace{1ex}} l }
                                \textbf{Programming Languages}: Python, R, SQL\\
                                \textbf{Data Science}: Pandas, Numpy, Scikit{-}Learn, t{-}SNE, Principal Component Analysis\\
                                \textbf{Data Science \& Machine Learning}: Scikit{-}Learn, t{-}SNE, Principal Component Analysis, Pandas, Numpy, Pyspark, Statistical Analysis, Forecasting\\
                                \textbf{Tools \& Technologies}: Flask, Jupyter Notebooks, Pyspark\\
                                \textbf{Visualization}: Seaborn, Matplotlib\\
                                \textbf{Data Visualization}: Seaborn, Matplotlib, Altair, Jupyter Notebooks\\
                                \textbf{Database Technologies}: Postgresql, SQLAlchemy, Redis, Sqlite\\
                                \textbf{Operating Systems}: CentOS, Ubuntu, Windows, MacOS\\
                                \textbf{Language Models}: OpenAI ChatGPT, NLTK, BERT\\
                                \textbf{Soft Skills}: Problem{-}solving, Communication skills, Cross{-}functional Collaboration\\
                        \textbf{Certifications:} 
                                            \href{}{\textbf{Statistics with R}},\\
                                 
        \end{tabular}
    \end{rSection}

\newcommand\myfontsize{\fontsize{0.1pt}{0.1pt}\selectfont} \myfontsize \color{white}
Data analysis, Quantitative analysis, Statistical packages, SQL, Business recommendations, Problem{-}solving, Communication skills, English proficiency, Collaboration, Data analysis, Quantitative analysis, Statistical packages, SQL, Business recommendations, Problem{-}solving, Communication skills, English proficiency, Collaboration, {artificial intelligence engineer, azure cognitive services exp, azure services, core azure services, azure cognitive and generative ai, genai, aws,  gcp, java, clean, efficient, maintainable code, react, front end, back end, ai solutions, data analysis, pretrained models, automl, software development principles, version control, testing, continuous integration and deployment, python, javascript, prompt engieering, frontend, backend, html, css, api, angular, development, machine learning, artificial intelligence, deep learning, data warehouse, data modeling, data extraction, data transformation, data loading, sql, etl, data quality, data governance, data privacy, data visualization, data controls, privacy, security, compliance, sla, aws, terabyte to petabyte scale data, full stack software development, cloud, security engineering, security architecture, ai/ml engineering, technical product management, microsoft office, google suite, visualization tools, scripting, coding, programming languages, analytical skills, collaboration, leadership, communication, presentation skills, computer vision, senior, ms or ph.d., 3d pose estimation, slam, robotics, object tracking, real-time systems, scalability, autonomy, robotic process automation, java, go, matlab, devops, ci/cd, programming, computer vision, data science, machine learning frameworks, deep learning toolsets, problem-solving, individual contributor, statistics, risk assessments, statistical modeling, apis, technical discussions, cross-functional teams}

\end{document}